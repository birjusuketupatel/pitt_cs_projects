yes sir yeah um you're looking at the
Chinese thought Chinese room a cloud
experiment yep oh you say so first off I
think that's a bad thought experiment I
think it's flawed that wasn't the idea I
was trying to give - okay what's the
idea you trying to get to me well first
uh um let's talk about why the Chinese
thought experiment I think fails so the
way I see it is um so basically the guys
in the Chinese uh the room and you know
he gets the message and then he
translates into Chinese and it goes on
there on the screen and people see it
correct
do you agree um I think so yeah it
sounded like he was saying you could ask
him questions but I could be wrong on
that it's just a translation you you can
ask them questions but he has an answer
to all the questions in this book like
yup in the book put it in and go up
gotcha okay so then the question is well
does that guy really know Chinese or see
just looking at okay and I would argue
that if that process is internalized it
would be the exact same thing that when
you ask a human a question that they
internally referred to things that
they've memorized or whatever knowingly
or unknowingly and then they spread out
an answer the difference is that the
whole process is internalized rather
than speaking about things like
discreetly I guess like in the Chinese
room thing yeah yeah I I agree with that
like I think the the guy in the machine
anyway knows Chinese because it imagined
this so like you know how our brains
like I mean I'm not under all like a
neuroscience but we have like you know
neurons firing in our brain all the time
but yeah so that would be like saying
like you know oh I can speak English but
do my neurons know English do they
really know English or they just sending
singles to me with what to say yeah okay
right so I mean if my I mean if you
imagine the little the guy in the room
like your neuron it would be absurd to
say oh no you don't really know Chinese
well then that's like saying you you're
yourself don't know English like you
were saying yes because it's your
neurons doing it yes I agree with you on
that point okay so now my issue with the
CPM is I think there's a first we need
to like agree with like the definitions
of what a computer is okay so to me I
think a computer is
something that manipulates syntax then
spits out cement
okay what do you mean by spits out
semantics they're so like you know so
the syntax is like all ones and zeros
and let's say like him this exact code
of ones and zeroes pushes up my discord
page okay
all right do you agree that yeah I
thought semantics spoke to more like an
internal like understanding of something
so for instance the the syntax of water
like in English as wate R but the
semantics of water is like the
experience of water that when I think of
water like everything I'm thinking abut
that would be the semantic part I
thought that I think I'm told softly I
think it's more it's the water yeah that
one that said yeah well yeah yeah but in
when we talk to people we talk about our
water right you're saying there it's
like I can imagine like if I drained um
water is pouring all over me
I won't say that was cement and like I
felt like in the dream water was pouring
on the oh and say oh that was semantics
right I'd say that's just my head wait
what well are you saying that it's just
a feeling
wait I thought syntax refers to specific
symbols that have no oh oh yeah no but
I'm just trying to draw a distinction
emergency I thought syntax just refers
to like a specific ordering of symbols
and whatnot that don't have any
intrinsic meaning behind them so like
John drank water like that could be a
syntax but it doesn't necessarily mean
anything but then the semantics of it
would be john is a human being that i
know drinking is the act of taking
something into the body and then water
is the substance and etham air that I
really like the semantics part of it
that's the difference here the syntax on
the semantics and the argument with the
Chinese thing is that computers can't
understand the syntax without ever
knowing the semantics right
yeah no syntax in the computer and it
comes up with the semantics right I'd
okay wait hold on
mm-hm what are you saying correct cuz
one of us has a big misunderstanding of
us in it but it might be me compute
Computers can't ever come up with
semantics right semantics are something
that would exist between people or
that's what we were arguing right that
things are what have semantics but the
commuters and deaf computers never have
Szymanski but you're saying that
computers are conscious no what I'm
saying is I don't know if I believe that
semantics necessarily exist that that
everything is syntax but they as you
appeal more and more and more syntax on
to each other that semantics becomes
sort of like an emergent thing of a
bunch of interacting syntax or whatever
I think you're saying yeah I just want
to make sure like we're on the same page
so we're not arguing for the same thing
and then the whole time we're confused
yeah so what's your theory of
consciousness like like what are you
trying to argue for okay so the before I
read that article my theory is that Myra
my idea I hated saying anything I have
as a theory but my idea is that
consciousness is literally just a place
that exists that exists to wait
decisions that's that's everything that
conscious is for like a human being so
like when we were trying to make
decisions the process of deciding
between multiple things or whatever
that's the experience of consciousness
that's what I would argue or what I
would it feels right to me um yeah I
mean kind of for me conscious I mean
like I get like you said it's hard to
define consciousness but the the common
view in philosophy is that they have
mental states right like I have a belief
that's the mental state me feeling pain
that's a mental state like if I if I'm
on fire I'm in a mental state of pain or
my belief that I'm talking to you right
now is a mental state because I'm
experiencing that okay right like you
would agree like Siri could not have a
belief like Siri doesn't believe
anything um no I well I don't know if
it's sufficiently complicated enough to
but I believe that machines could have
beliefs sure in what sense do you think
we could hold their own beliefs sure so
let's say that I give a computer the
ability to let's say we work with a few
to sensory inputs okay the sense of
temperature so the ability to perceive
temperature and then sight the ability
to see things so let's say that I give
this computer an absurd amount of
programming to make it understand what
fire is okay that fire is something that
you know we all the physical definitions
you know when something is come by
bullying burns and all that [ __ ] that
that fire is very hot that if you touch
it you will and increase the temperature
you know it glows typically it emits
light that I could do this right I could
put this this thing that I've programmed
I could put it in a room and then on the
other side of the door oh and and and
maybe I could give it sound as well the
ability to perceive sound so hearing I
could put this thing in a room light a
fire on the other side of the door and
then the computer could walk up to this
door touch the handle feel that the
handle is fought feel that the handle is
hot see the light coming from beneath
the door and then hear the crackle on
the other room and then without ever
knowing it it could believe that there's
a fire on the other side of the door
does this qualify as being a belief in
your book or is it something different
yes saying that the the computer even
though it's incorrect would believe
there's a fire yeah well it's not
necessarily incorrect but it could be
incorrect sure but that yeah yeah so um
now what I would say that that then is
well you just programmed the computer
that way it's just programmed to do that
when it sure experience but then I was I
would ask you what the difference is
between a human because humans don't
have any intrinsic knowledge of fire we
have we would train humans the same way
you have to perceive fire existing as
you perceive fire oftentimes you have to
interact with it to know that it's hot
this is why children touch stoves or
touch candles and they're stupid once
you have that sensory perception then
you begin to extrapolate right if you
ever see or hear something that's
crackling and very hot like I feel like
humans learn about it the exact same way
the machine would kind of not what's
this so like for me like it again it's a
really complex issue and I'm not coming
on you're saying oh I have all the
answers all my answers are from like
philosophers who thought of this stuff
way better than me sure so but I would
then I would ask like from the
philosophical point of view what would
be the difference between a human has a
famous book called what it is like to be
a bat is a hard problem of consciousness
I acknowledge that this is a thing but
but I'm well but I'm carries on the
specific thing or a saccharide finish oh
yeah
the idea that there is something like to
be a computer like how would a computer
think other than just spitting out the
semantics when it's manipulating syntax
sure but we've moved but but you could
apply this type of humans it would fail
equally well what for instance what is
it like to have a vaginal Oregon
I'm making an assumption based on the on
the timbre of your voice but I don't
think you're a female I don't think you
have a vagina you could never know the
answer to that question are women
conscious yeah I think so but why why do
I think so I think that um consciousness
probably comes from something biological
habit had it but now we're like in play
but why why do I think that I'm sorry
before going off into this all I'm
saying is that like I just I pointed out
a perception that you will never be able
to experience you have no idea or like
what is it like to birth a child or to
be pregnant right these are sensory
things that you can never perceive you
will never be able to perceive these and
even more generally we could speak to
general senses for instance if I were to
ask you what does the color red look
like you cannot describe that to me or
rather what you know what does a note of
music sound like you could never give me
a description of these things you just
assume that other people interpret it
the same way that you do but you can't
really know so I could argue that that a
machine could be the exact same way the
machine could perceive these things and
have a conscious where it weighs these
kinds of things but just because it's a
machine I don't know do you understand
I'm going or no I it's like it's almost
humanistic of me to think that oh well
it doesn't have like my kind of body
parts or like you know species then of
course it can do that so what I would
say the you then so would you then be
are you trying to say then that if like
a computer passed the Turing test it
could then think what I'm saying is that
our way of understanding consciousness
from other people is always and will
likely all I shouldn't have but is has
always been and for the foreseeable
future will be done in an external sense
that if somebody were to create a human
and then create a computer program and
both of them could give me the exact
same outputs as one another I would have
no basis of which to say one is
conscious and one isn't there's no way
that kind of a functionalist sure well
the functionalist sounds like it goes
hand in hand with that computational
theory of mind okay imagine there is um
have you heard of this super-stoked
problem
so the super stoic is imagine a guy he
is just stoic he shows no emotion shows
no pain shows nothing is just like a
strong guy and if our best knowledge of
what's conscious is how they kind of
function in certain things and how they
learn if I am let a super stoic on fire
and he just sat there he's in flinch he
just sat there on fire
would you say that he's in pain um no
really I disagree I think you'd be in
pain well but so this is it so [ __ ] okay
so I'm not trying to catch you on a
technicality here but I could actually
prove you wrong with medical science
there are people that are actually born
with the inability to perceive pain it's
a really [ __ ] up disorder because he's
super technical but like no let's say
for sake of argument though that he was
just a super stoic sure I'm sure but I
can never truly know I can't say if he's
if he feels pain or not it's impossible
for me to know that I can make an
assumption but yeah but this is like um
I mean like we could even argue about
degrees of pain like I don't know if we
could even agree that we perceive pain
in the same way right for instance there
are some people that um you know can get
a shot and don't care if they could get
rabies shots and aren't even that
bothered by it right which are which are
horrible and there are other people who
get a shot and it's like excruciating
for them like even adults that kind of
cry when when they get shot now can you
argue that one person is more stoic than
the other or can you argue that one
person doesn't perceive the pain as much
as the other person how could you
possibly know that as an external
observer there's no way we could know
for sure but I mean it does come to a
place where your intuitions take you I
mean and I usually don't form arguments
on intuition and how you feel both
something like so mysterious and complex
is consciousness like you're okay what
people say in that correct that it's
mysterious that it's what like like
sometimes were to look to our intuitions
to see what consciousness it no I hate I
hate all arguments of enjoy your night
yeah
for it took philosophy of mind I was not
like you know intuitions screw that but
it's so hard to prove anything's
conscious like then how did like I'd say
to you how do you know I'm conscious
then if you can't prove it I can't
possibly know that that was what I was
screaming at you and I was just I know
you don't believe anyone's conscious but
yourself that I mean I can make
arguments I can kind of inductively
reason based on our similarities that
you're conscious but that's not a that's
not a full proof that's not a deductive
analysis I can't make factual claims
like maybe this sounds a little
scientifically anti-realist I don't know
this equalities that but like I I can
assume that you're conscious because you
and me share many similarities but that
doesn't but I can't really truly say and
and I and I wouldn't even be comfortable
making statements that like we perceive
things the same either like I that would
be something that there's allies ever
like why do some people like some music
and not like other music I don't know if
we all perceive music the same as well
you know like that's something that's
impossible to say mm-hmm so yeah you so
I agree what you're saying and good if
you said to me right now that you know
uh I only think I'm conscious I don't
think we could have had this
conversation because it'd be ridiculous
right um so then like where does the
line go for you then when you start
saying that's conscious and that's not
I'm just trying to feel out what were
you're coming from so like I don't even
know what conscious means so this is
like my working
I have no engaged zero engagement with
any literature here okay so I'm totally
[ __ ] beyond blaming here okay so my
what I feel like people so I feel like
what we think is conscious is determined
in an intuitive sense I think that we
intuitively feel it out we don't
rationally think about it so what I
perceive to be as conscious is
oftentimes indecision or or time taken
to make decisions and then emotional
responses to things so for instance um
so let me let me think of an example the
first thing typically one thing that I
think quote unquote
feels conscious is when people take time
to make decisions so when I ask you a
question that pause between thinking of
the answer is something that I interpret
is conscious like it sounds like there's
some kind of type of internal thing
going on to extrapolate this to like the
machine world
if our graphing calculators if you could
add a smiley face or a frowny face or
something to like a ti-84 or ti-85 right
and then when you push the problem if
you're like calculating like complicated
like like radials or some sugar or
integrals on armor of you doesn't say 85
I'm not right that if they were to have
like a little face that like put like a
thinking face or something that
intuitively is a human because it's
taking time to think of that answer I
think that you would interpret that in
an intuitive sense as being somewhat
conscious now you would obviously say no
because it's a machine hahahaha but you
would be more likely to empathize with
it in terms of like a conscientious
thing do you agree with that or disagree
with that
yeah I agree that I would definitely
emphasize like I mean it's like um if I
had a robot that like you're yourself
called zombies right I don't but people
keep bringing it up
oh so philosophical zombie is just the
idea that it's possible that there could
be humans like us they function in the
same way they are identical every single
point except there's no consciousness oh
I see yes I understand yeah I see it
yeah there's nothing behind there right
there's nothing like to be philosophical
zombie Tyler there's something like to
be philosophical zombie Steve yeah
you've ever Steven or Steve I don't care
either one is Steven actually okay yeah
so that would be a philosophical zombie
oh do you think those things couldn't
exist or it could exist yeah I would I
would have to say it could exist for
sure cuz it's cuz it's yeah so then if I
lit let's say well I won't use you
because it sounds morbid than if I lit
philosophical zombie Tyler on fire and
he's like freaking out like ah [ __ ] like
I'm in pain because he's a functional
functional duplicate would you say he's
conscious then cuz she seems to be
experiencing pain oh I don't I don't
even know if I necessarily I'm sorry
maybe we should ground this person I
don't know if I necessarily even believe
in consciousness and like that as like
yeah sorry maybe we should have started
there yeah yeah that's right when I use
conscious when I said maybe when I say
when I say the word conscious I'm
referring to like what would our current
like what people mean but but for me I
just view consciousness as kind of like
an emergent property of systems that are
trying to make decisions is all I view
it as that so this okay so if you
understand my working definition there
then you can understand more how I could
view that like machines
have consciousness because of their
nationally complicated I'm making
because I'm coming from the idea that
like consciousness it's like usually
they have like mental states right like
